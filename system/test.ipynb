{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "\n",
    "class FedAvgCNN(nn.Module):\n",
    "    def __init__(self, in_features=1, num_classes=10, dim=1024):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_features,\n",
    "                        32,\n",
    "                        kernel_size=5,\n",
    "                        padding=0,\n",
    "                        stride=1,\n",
    "                        bias=True),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32,\n",
    "                        64,\n",
    "                        kernel_size=5,\n",
    "                        padding=0,\n",
    "                        stride=1,\n",
    "                        bias=True),\n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(dim, 512), \n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "m = FedAvgCNN()\n",
    "if isinstance(m,FedAvgCNN):\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "dataset = \"Cifar100\"\n",
    "idx = 5\n",
    "train_data_dir = os.path.join('../dataset', dataset, 'train/')\n",
    "\n",
    "train_file = train_data_dir + str(idx) + '.npz'\n",
    "with open(train_file, 'rb') as f:\n",
    "    npzfile = np.load(f, allow_pickle=True)\n",
    "    # 打印所有可用的键\n",
    "    print(list(npzfile.keys()))\n",
    "\n",
    "    # 检查 'data' 键是否存在\n",
    "    if 'data' in npzfile:\n",
    "        train_data = npzfile['data'].tolist()\n",
    "    else:\n",
    "        print(\"'data' key not found in the npz file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_hook(module, input, output):\n",
    "    # 这里的output就是经过该模块的中间输出\n",
    "    # 你可以把它保存下来\n",
    "    print(\"Shape of output:\", output.shape) \n",
    "\n",
    "\n",
    "model = FedAvgCNN()\n",
    "# 假设我们想要获取conv2层的中间表征\n",
    "hook = model.conv2.register_forward_hook(get_features_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"models\\Cifar100\\FedTrans_server_attn.pt\")\n",
    "emb_layer = model['emb_layer']\n",
    "intra_attn_model = model['intra_attn_model']\n",
    "psub_res = torch.load(\"psub_res.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(psub_res[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = intra_attn_model\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name, param.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([emb_layer(p) for p in psub_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.size())\n",
    "X_mean = torch.mean(x, dim=0)\n",
    "X_std = torch.std(x, dim=0)\n",
    "X_norm = (x - X_mean) / X_std\n",
    "print(X_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = intra_attn_model(X_norm)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = intra_attn_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = intra_attn_model.query(x)\n",
    "k = intra_attn_model.key(x)\n",
    "print(q,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "cosine_similarity = F.cosine_similarity(q[0].unsqueeze(0),q[1].unsqueeze(0))\n",
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flcore.servers.serverfedtrans import Attn_Model\n",
    "device = \"cuda:0\"\n",
    "x.to(device)\n",
    "attn_model = Attn_Model().to(device)\n",
    "weights = attn_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psub_res = torch.load(\"psub_res.pth\")\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = torch.dot(a, b)\n",
    "    norm_a = torch.norm(a)\n",
    "    norm_b = torch.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "print(cosine_similarity(psub_res[1],psub_res[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(psub_res[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = torch.load(\"models\\Cifar10\\FedTrans_server_attn.pt\")\n",
    "intra_attn_model = attn_model['intra_attn_model']\n",
    "\n",
    "psub_res = [p.unsqueeze(0) for p in psub_res]\n",
    "\n",
    "x = torch.cat(psub_res, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flcore.servers.serverfedtrans import Attn_Model\n",
    "attn_model2 = Attn_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in emb_layer.named_parameters():\n",
    "    print(f\"Layer: {name}, Size: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = nn.Linear(x.size(1),intra_attn_model.query.weight.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_list = [psub for psub in psub_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_e, iter_w = res['inter_clusters_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iter_e[1].size())\n",
    "\n",
    "x = torch.cat(iter_e, dim=0).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Attn_Model_C(nn.Module):\n",
    "    def __init__(self, emb_dim=128, attn_dim=128, num_heads=8):\n",
    "        super(Attn_Model_C, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.attn_dim = attn_dim\n",
    "        self.query = nn.Linear(emb_dim, attn_dim)\n",
    "        self.key = nn.Linear(emb_dim, attn_dim)\n",
    "        #self.inter_LN = nn.LayerNorm(attn_dim)\n",
    "\n",
    "        # 1-layer attention for simple verify\n",
    "\n",
    "    def forward(self, x, models=None, prev_models=None):\n",
    "        #x = self.inter_LN(x) \n",
    "        q = self.query(x)\n",
    "\n",
    "        k = self.key(x)\n",
    "        print(\"q:{}\\n{}\\nk:{}\".format(q,\"-\"*5,k))\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) \n",
    "        #scores = torch.matmul(q, k.transpose(-2, -1)) / (self.attn_dim ** 0.2)\n",
    "        print(scores)\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attn_model_1 = Attn_Model_C().to(device)\n",
    "w = attn_model(x.to(device))\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in res['intra_clusters_res']:\n",
    "    if c is not None:\n",
    "        c_e = c[0]\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    x = torch.cat(c_e, dim=0).squeeze(1)\n",
    "    w = attn_model_1(x.to(device))\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(res['intra_clusters_res'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"gm_avg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "ps = []\n",
    "param = [p.view(-1) for p in model.parameters()]\n",
    "ps = torch.concat(param, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试attn参数backward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "model1 = torch.nn.Linear(10, 20)\n",
    "model2 = torch.nn.Linear(10, 20)\n",
    "emb_layer = torch.nn.Linear(220, 128)\n",
    "for p_1, p_2 in zip(model1.parameters(), model2.parameters()):\n",
    "    p_1.data += p_2.data\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "model1 = torch.nn.Linear(10, 20)\n",
    "model2 = torch.nn.Linear(10, 20)\n",
    "sd1 = model1.state_dict()\n",
    "sd2 = model2.state_dict()\n",
    "sd3 = OrderedDict()\n",
    "for name, param in model1.named_parameters():\n",
    "    sd3[name] = param.data.clone()\n",
    "print(\"sd1:{}\\nsd3:{}\".format(sd1,sd3))\n",
    "#for name, param in model1.named_parameters():\n",
    "#    sd2[name] = param.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn_Model(nn.Module):\n",
    "    def __init__(self, emb_dim=128, attn_dim=128, num_heads=8):\n",
    "        super(Attn_Model, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.attn_dim = attn_dim\n",
    "        self.query = nn.Linear(emb_dim, attn_dim)\n",
    "        self.key = nn.Linear(emb_dim, attn_dim)\n",
    "        #self.inter_LN = nn.LayerNorm(attn_dim)\n",
    "\n",
    "        # 1-layer attention for simple verify\n",
    "\n",
    "    def forward(self, x, models=None, prev_models=None):\n",
    "        #x = self.inter_LN(x) \n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) \n",
    "\n",
    "        #scaled coef removed since we want to diff weight matrix entries\n",
    "        #scores = torch.matmul(q, k.transpose(-2, -1)) / (self.attn_dim ** 0.5)\n",
    "        attention_weights = torch.softmax(scores, dim=-1)\n",
    "        return attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "##\n",
    "def w_add_params(global_model, m_weights, models_params, require_grad=False):\n",
    "    params = [] \n",
    "    res = copy.deepcopy(global_model)\n",
    "    for param in res.parameters():\n",
    "        param.data.zero_()\n",
    "            \n",
    "    for w, model_params in zip(m_weights, models_params):\n",
    "        for res_param, model_param in zip(res.parameters(), model_params):\n",
    "            if require_grad:\n",
    "                res_param.grad += model_param.grad.clone().detach() * w\n",
    "            res_param.data += model_param.data.clone().detach() * w\n",
    "    return res\n",
    "        \n",
    "        \n",
    "\n",
    "def emb(phead,emb_layer):\n",
    "    params = []\n",
    "    for p in phead.parameters():\n",
    "        params.append(p.flatten())\n",
    "    params = torch.cat(params)\n",
    "    return emb_layer(params)\n",
    "\n",
    "\n",
    "def weight_flatten(model):\n",
    "    params = []\n",
    "    for u in model.parameters():\n",
    "        params.append(u.view(-1))\n",
    "    params = torch.cat(params)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建模型以及计算weighted sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [nn.Linear(10,20) for i in range(10)]\n",
    "flatten_models = [weight_flatten(model) for model in models]\n",
    "emb_layer = nn.Linear(len(flatten_models[0]), 128)\n",
    "models_emb = [emb(model, emb_layer) for model in models]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat([e.reshape(1,-1) for e in models_emb], dim=0)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_model = Attn_Model()\n",
    "\n",
    "weights = attn_model(x)\n",
    "print(weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 暂时关闭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ms = []\n",
    "for i in range(weights.size()[0]):\n",
    "    w = [weights[i][j] for j in range(weights[i].size()[0])]\n",
    "    sd = copy.deepcopy(models[i].state_dict())\n",
    "    new_m = w_add_parameters(models[0], w, [model for model in models])\n",
    "    new_ms.append(new_m)\n",
    "print(len(new_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = nn.utils.parameters_to_vector(models[0].parameters())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 暂时关闭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = new_ms\n",
    "inner_optimizers = [torch.optim.SGD(models[i].parameters(),\\\n",
    "                                lr=0.005) for i in range(10)]\n",
    "inner_states = [copy.deepcopy(m.state_dict()) for m in models]\n",
    "\n",
    "for i in range(10):\n",
    "    #one-step local training\n",
    "    inp = torch.rand([10])\n",
    "    y = torch.rand([20])\n",
    "    mseloss = torch.nn.MSELoss()\n",
    "    #print(\"prev_model:{}\".format(nn.utils.parameters_to_vector(models[i].parameters())))\n",
    "    output = models[i](inp)\n",
    "    loss = mseloss(output, y)\n",
    "    loss.backward()\n",
    "    inner_optimizers[i].step()\n",
    "    #print(\"cur_model:{}\".format(nn.utils.parameters_to_vector(models[0].parameters())))\n",
    "final_states = [m.state_dict() for m in models]\n",
    "delta_thetas = [OrderedDict({k: inner_states[i][k] - final_states[i][k] for k in models[i].state_dict().keys()}) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试模型参数修改函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "model = models[0]\n",
    "# 我想修改的模型state\n",
    "sd = model.state_dict()\n",
    "w = weights[0]\n",
    "# 用一个带grad的weight去aggregate模型参数\n",
    "# 把参数放回state，保存带梯度的参数到另外一个list，用于梯度计算\n",
    "print(sd)\n",
    "\n",
    "def w_add_parameters(sd, w, models):\n",
    "    sg = OrderedDict()\n",
    "    for w_i, model in zip(w, models):\n",
    "        for key in sd.keys():\n",
    "            if key not in sg.keys():\n",
    "                sg[key] = w_i * model.state_dict()[key]\n",
    "            else:\n",
    "                sg[key] = sg[key] + w_i * model.state_dict()[key]\n",
    "            print(sg)\n",
    "            sd[key] = sd[key] + sg[key].data\n",
    "    return sg, sd\n",
    "sg, sd = w_add_parameters(sd, w, models)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 更新模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = models[0]\n",
    "## 我想修改的模型state\n",
    "#sd = model.state_dict()\n",
    "#w = weights[0]\n",
    "## 用一个带grad的weight去aggregate模型参数\n",
    "## 把参数放回state，保存带梯度的参数到另外一个list，用于梯度计算\n",
    "\n",
    "#sg, sd = w_add_parameters(sd, w, models)\n",
    "\n",
    "inner_state = sd\n",
    "nm = nn.Linear(10,20)\n",
    "nm.load_state_dict(sd)\n",
    "inner_optimizer = torch.optim.SGD(nm.parameters(),lr=0.05)\n",
    "inner_state = copy.deepcopy(nm.state_dict())\n",
    "for _ in range(10):\n",
    "    inp = torch.rand([10])\n",
    "    y = torch.rand([20])\n",
    "    mseloss = torch.nn.MSELoss()\n",
    "    #print(\"prev_model:{}\".format(nn.utils.parameters_to_vector(models[i].parameters())))\n",
    "    output = nm(inp)\n",
    "    loss = mseloss(output, y)\n",
    "    loss.backward()\n",
    "    inner_optimizer.step()\n",
    "final_state = nm.state_dict()\n",
    "delta_theta = OrderedDict({k:inner_state[k]-final_state[k] for k in nm.state_dict().keys()})\n",
    "\n",
    "lv = list(sg.values())\n",
    "param_list = list(attn_model.parameters())\n",
    "param_list.extend(emb_layer.parameters())\n",
    "params_grads = torch.autograd.grad(lv,param_list,grad_outputs=list(delta_theta.values()),retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_state = copy.deepcopy(attn_model.state_dict())\n",
    "emb_state = copy.deepcopy(emb_layer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "at_state_1 = copy.deepcopy(attn_model.state_dict())\n",
    "emb_state_1 = copy.deepcopy(emb_layer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "optimizer = torch.optim.SGD(\n",
    "            [\n",
    "                {'params': [p for p in param_list]},\n",
    "            ], lr=lr, momentum=0.9\n",
    "        )\n",
    "for p, g in zip(param_list, params_grads):\n",
    "            p.grad = g\n",
    "torch.nn.utils.clip_grad_norm_(param_list, 50)\n",
    "\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in param_list:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_optimizer = torch.optim.SGD(nm.parameters(),lr=0.05)\n",
    "inner_state = copy.deepcopy(nm.state_dict())\n",
    "print(inner_state)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for _ in range(10):\n",
    "    inp = torch.rand([10])\n",
    "    y = torch.rand([20])\n",
    "    mseloss = torch.nn.MSELoss()\n",
    "    #print(\"prev_model:{}\".format(nn.utils.parameters_to_vector(models[i].parameters())))\n",
    "    output = nm(inp)\n",
    "    loss = mseloss(output, y)\n",
    "    loss.backward()\n",
    "    inner_optimizer.step()\n",
    "final_state = nm.state_dict()\n",
    "delta_theta = OrderedDict({k:inner_state[k]-final_state[k] for k in nm.state_dict().keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inner_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算JVP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "attn_optimizer = torch.optim.SGD(\n",
    "    [\n",
    "        {'params' : [p for p in attn_model.parameters()]} ,\n",
    "        {'params' : [p for p in emb_layer.parameters()]}\n",
    "    ], lr=lr, momentum=0.9)\n",
    "\n",
    "param_list = list(attn_model.parameters())\n",
    "param_list.extend(emb_layer.parameters())\n",
    "attn_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = [\n",
    "            torch.autograd.grad([p for p in model.parameters()], param_list , grad_outputs=list(delta_theta.values()))\\\n",
    "            for model, delta_theta in zip(models,delta_thetas)\n",
    "        ]      \n",
    "for grad in grads:\n",
    "    for param, g in zip(param_list, grad):\n",
    "        param.grad += grad \n",
    "\n",
    "torch.nn.utils.clip_grad_norm_(param_list, 50)\n",
    "attn_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_states = model[0]\n",
    "final_states = .state_dict()\n",
    "\n",
    "# calculating delta theta\n",
    "delta_theta = OrderedDict({k: inner_state[k] - final_state[k] for k in weights.keys()})\n",
    "\n",
    "# calculating phi gradient\n",
    "hnet_grads = torch.autograd.grad(\n",
    "    list(weights.values()), hnet.parameters(), grad_outputs=list(delta_theta.values())\n",
    ")\n",
    "\n",
    "print(torch.cat(g_1,dim=0).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models[0].state_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo = nn.Linear(10,20)\n",
    "mo.load_state_dict(new_ms[0].state_dict())\n",
    "print(mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in mo.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "res = copy.deepcopy(model1)\n",
    "for param in res.parameters():\n",
    "    param.data.zero_()\n",
    "\n",
    "for rp, p in zip(res.parameters(), model1.parameters()):\n",
    "    rp.data += p.data.clone()\n",
    "    \n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stri = \"../data\\\\mnist\"\n",
    "stri = stri.replace(\"\\\\\",\"/\")\n",
    "print(stri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.optim.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "api = wandb.Api()\n",
    "run = api.run(\"gerid/fedtrans_exp/t1zr3o00\")\n",
    "max = 0\n",
    "std = 0\n",
    "for i, row in run.history().iterrows():\n",
    "    if max < row[\"test_acc\"]:\n",
    "        max = row[\"test_acc\"]\n",
    "        std = row[\"std_acc\"]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = nn.MultiheadAttention(d_model, num_heads)\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        Q = self.q_linear(query)\n",
    "        K = self.k_linear(key)\n",
    "        V = self.v_linear(value)\n",
    "        out, _ = self.attention(Q, K, V, attn_mask=mask)\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForwardNetwork(d_model, d_ff)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_output = self.attention(x, x, x, mask)\n",
    "        x = x + attn_output\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = x + ff_output\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForwardNetwork(d_model, d_ff)\n",
    "\n",
    "    def forward(self, x, enc_out, mask=None):\n",
    "        attn_output = self.attention(x, x, x, mask)\n",
    "        x = x + attn_output\n",
    "        attn_output = self.attention(x, enc_out, enc_out)\n",
    "        x = x + attn_output\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = x + ff_output\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_encoder_layers, num_decoder_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff) for _ in range(num_encoder_layers)])\n",
    "        self.decoder = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff) for _ in range(num_decoder_layers)])\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        for layer in self.encoder:\n",
    "            src = layer(src, src_mask)\n",
    "        for layer in self.decoder:\n",
    "            tgt = layer(tgt, src, tgt_mask)\n",
    "        return tgt\n",
    "\n",
    "# Example usage:\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "\n",
    "transformer = Transformer(d_model, num_heads, d_ff, num_encoder_layers, num_decoder_layers)\n",
    "\n",
    "# Dummy data\n",
    "src = torch.rand((10, 32, d_model))  # (seq_len, batch, d_model)\n",
    "tgt = torch.rand((20, 32, d_model))  # (seq_len, batch, d_model)\n",
    "\n",
    "out = transformer(src, tgt)\n",
    "print(out.shape)  # Should be torch.Size([20, 32, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# 生成100个原始数据点\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# 初始化插值后的数据点\n",
    "x_new = np.linspace(0, 10, 1000)\n",
    "y_new = []\n",
    "\n",
    "# 对每一对相邻的原始数据点进行随机插值\n",
    "for i in range(len(x) - 1):\n",
    "    x_range = x[i:i + 2]\n",
    "    y_range = y[i:i + 2]\n",
    "\n",
    "    # 在只有两个点的情况下，只使用线性插值\n",
    "    method = 'linear'\n",
    "    \n",
    "    f = interp1d(x_range, y_range, kind=method)\n",
    "    x_interp = np.linspace(x_range[0], x_range[1], 10)  # 在每对相邻点之间生成10个新点\n",
    "    y_interp = f(x_interp)\n",
    "    \n",
    "    y_new.extend(y_interp)\n",
    "\n",
    "# 画图\n",
    "plt.figure()\n",
    "plt.scatter(x, y, label='Original Points')\n",
    "plt.plot(x_new, y_new, label='Interpolated Points')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# 生成100个原始数据点\n",
    "x = np.linspace(0, 10, 10)\n",
    "y = np.sin(x)\n",
    "\n",
    "# 初始化插值后的数据点\n",
    "x_new = np.linspace(0, 10, 1000)\n",
    "y_new = []\n",
    "\n",
    "# 对每一对相邻的原始数据点进行随机插值\n",
    "for i in range(len(x) - 1):\n",
    "    x_range = x[i:i + 2]\n",
    "    y_range = y[i:i + 2]\n",
    "\n",
    "    # 在只有两个点的情况下，只使用线性插值\n",
    "    method = 'linear'\n",
    "    \n",
    "    f = interp1d(x_range, y_range, kind=method)\n",
    "    x_interp = np.linspace(x_range[0], x_range[1], 10)  # 在每对相邻点之间生成10个新点\n",
    "    y_interp = f(x_interp)\n",
    "    \n",
    "    # 添加随机噪声\n",
    "    noise = 0.1 * np.random.normal(size=len(y_interp))\n",
    "    y_interp += noise\n",
    "    \n",
    "    y_new.extend(y_interp)\n",
    "\n",
    "# 画图\n",
    "plt.figure()\n",
    "plt.scatter(x, y, label='Original Points')\n",
    "plt.plot(x_new, y_new, label='Interpolated Points')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# 生成10个原始数据点\n",
    "x = np.linspace(0, 10, 10)\n",
    "y = np.sin(x)\n",
    "\n",
    "# 初始化插值后的数据点\n",
    "x_new = np.linspace(0, 10, 1000)\n",
    "y_new = []\n",
    "\n",
    "# 对每一对相邻的原始数据点进行随机插值\n",
    "for i in range(len(x) - 1):\n",
    "    x_range = x[i:i + 2]\n",
    "    y_range = y[i:i + 2]\n",
    "\n",
    "    # 在只有两个点的情况下，只使用线性插值\n",
    "    method = 'linear'\n",
    "    \n",
    "    f = interp1d(x_range, y_range, kind=method)\n",
    "    x_interp = np.linspace(x_range[0], x_range[1], 100)  # 在每对相邻点之间生成100个新点\n",
    "    y_interp = f(x_interp)\n",
    "    \n",
    "    # 添加随机噪声\n",
    "    noise = 0.1 * np.random.normal(size=len(y_interp))\n",
    "    y_interp += noise\n",
    "    \n",
    "    y_new.extend(y_interp)\n",
    "\n",
    "# 画图\n",
    "plt.figure()\n",
    "plt.scatter(x, y, label='Original Points', c='red')\n",
    "plt.plot(x_new, y_new, label='Interpolated Points')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# 生成10个原始数据点\n",
    "x = np.linspace(0, 10, 10)\n",
    "y = np.sin(x)\n",
    "\n",
    "# 初始化插值后的数据点列表\n",
    "y_new = []\n",
    "\n",
    "# 对每一对相邻的原始数据点进行随机插值\n",
    "for i in range(len(x) - 1):\n",
    "    x_range = x[i:i + 2]\n",
    "    y_range = y[i:i + 2]\n",
    "\n",
    "    # 使用线性插值\n",
    "    method = 'linear'\n",
    "    \n",
    "    f = interp1d(x_range, y_range, kind=method)\n",
    "    x_interp = np.linspace(x_range[0], x_range[1], 111)  # 在每对相邻点之间生成111个新点\n",
    "    y_interp = f(x_interp)\n",
    "    \n",
    "    # 添加随机噪声\n",
    "    noise = 0.1 * np.random.normal(size=len(y_interp))\n",
    "    y_interp += noise\n",
    "    \n",
    "    # 除了最后一次迭代，去掉每次插值的最后一个点以避免重复\n",
    "    if i < len(x) - 2:\n",
    "        y_new.extend(y_interp[:-1])\n",
    "    else:\n",
    "        y_new.extend(y_interp)\n",
    "\n",
    "# 创建新的x轴数据点\n",
    "x_new = np.linspace(0, 10, len(y_new))\n",
    "\n",
    "# 画图\n",
    "plt.figure()\n",
    "plt.scatter(x, y, label='Original Points', c='red')\n",
    "plt.plot(x_new, y_new, label='Interpolated Points')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beb37d7b78bf3788f54259aa41c6c1e59fac34bf95ae5ff22b978ccc20cf7a1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
